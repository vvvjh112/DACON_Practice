{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import glob\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "import torchvision.models as models\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "CFG = {\n",
        "    'IMG_SIZE': 224,\n",
        "    'EPOCHS': 5,\n",
        "    'LEARNING_RATE': 3e-4,\n",
        "    'BATCH_SIZE': 32,\n",
        "    'SEED': 41\n",
        "}\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed) ##random module\uc758 \uc2dc\ub4dc \uace0\uc815\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed) #\ud574\uc2dc \ud568\uc218\uc758 \ub79c\ub364\uc131 \uc81c\uc5b4, \uc790\ub8cc\uad6c\uc870 \uc2e4\ud589\ud560 \ub54c \ub3d9\uc77c\ud55c \uc21c\uc11c \uace0\uc815\n",
        "    np.random.seed(seed) #numpy \ub79c\ub364 \uc22b\uc790 \uc77c\uc815\n",
        "    torch.manual_seed(seed) # torch\ub77c\uc774\ube0c\ub7ec\ub9ac\uc5d0\uc11c cpu \ud150\uc11c \uc0dd\uc131 \ub79c\ub364 \uc2dc\ub4dc \uace0\uc815\n",
        "    torch.cuda.manual_seed(seed) # cuda\uc758 gpu\ud150\uc11c\uc5d0 \ub300\ud55c \uc2dc\ub4dc \uace0\uc815\n",
        "    torch.backends.cudnn.deterministic = True # \ubc31\uc5d4\ub4dc\uac00 \uacb0\uc815\uc801 \uc54c\uace0\ub9ac\uc998\ub9cc \uc0ac\uc6a9\ud558\ub3c4\ub85d \uace0\uc815\n",
        "    torch.backends.cudnn.benchmark = True # CuDNN\uc774 \uc5ec\ub7ec \ub0b4\ubd80 \ud734\ub9ac\uc2a4\ud2f1\uc744 \uc0ac\uc6a9\ud558\uc5ec \uac00\uc7a5 \ube60\ub978 \uc54c\uace0\ub9ac\uc998 \ub3d9\uc801\uc73c\ub85c \ucc3e\ub3c4\ub85d \uc124\uc815\n",
        "\n",
        "df = pd.read_csv('dataset/train.csv')\n",
        "# df['img_path'] = df['img_path'].apply(lambda x:os.path.join('dataset',x[1:]))\n",
        "train, val, _, _ = train_test_split(df, df['label'], test_size=0.3, stratify=df['label'], random_state=CFG['SEED'])\n",
        "\n",
        "le = preprocessing.LabelEncoder() # \ub77c\ubca8\uc778\ucf54\ub529 /\ub77c\ubca8(\ubaa9\ud45c \ubcc0\uc218)\ub97c \uc815\uc218\ub85c \uc778\ucf54\ub529\n",
        "# train, label\uc758 \ub77c\ubca8\uc778\ucf54\ub529 \uacfc\uc815 \uc9c4\ud589\n",
        "train['label'] = le.fit_transform(train['label'])\n",
        "val['label'] = le.transform(val['label'])\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    ## \ud30c\uc77c \uacbd\ub85c\uc640 \ub77c\ubca8\uc744 \ubc1b\uc544, \ub370\uc774\ud130\ub97c \ub85c\ub4dc\ud558\uace0 \uc804\ucc98\ub9ac\ud558\ub294 \ub370\uc774\ud130\uc14b \uc0dd\uc131\uc131\n",
        "    def __init__(self, img_path_list, label_list, transforms=None):\n",
        "        self.img_path_list = img_path_list\n",
        "        self.label_list = label_list\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.img_path_list[index]\n",
        "\n",
        "        # \uc774\ubbf8\uc9c0 \uc77d\uc5b4\uc624\uae30\n",
        "        image = cv2.imread(img_path)\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(image=image)['image']\n",
        "\n",
        "        # \ub77c\ubca8\uc774 \uc788\ub2e4\uba74 \uc774\ubbf8\uc9c0\uc640 \ud568\uaed8 \ubc18\ud658\n",
        "        if self.label_list is not None:\n",
        "            label = self.label_list[index]\n",
        "            return image, label\n",
        "        # \ub77c\ubca8\uc774 \uc5c6\ub2e4\uba74 \uc774\ubbf8\uc9c0\ub9cc \ubc18\ud658\ud658\n",
        "        else:\n",
        "            return image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_path_list)\n",
        "\n",
        "\n",
        "# Compose\ub294 \uc5ec\ub7ec \ubcc0\ud658\uc744 \uc5f0\uc18d\uc801\uc73c\ub85c\uc801\uc6a9\ud560 \uc218 \uc788\uac8c \ud574\uc8fc\ub294 \ud568\uc218. (IMG \uc0ac\uc774\uc988 224\ub85c \uc124\uc815\ub418\uc5b4 \uc788\uc74c)\n",
        "# \uc774\ubbf8\uc9c0 \ud06c\uae30\uc870\uc815, \uc815\uad6c\ud654, \ud150\uc11c\ub85c \ubcc0\ud658 \ud3ec\ud568.\n",
        "'''\n",
        "Normalize(mean=0.485, 0.456, 0.406\uac12\uc740 \uac01 \ucc44\ub110\ubcc4 \ud3c9\uade0)\n",
        "std=(0.229, 0.224, 0.225 \uac12\uc740 \uac01 \ucc44\ub110\ubcc4 \ud45c\uc900\ud3b8\ucc28)\n",
        "max_pixel_value: \uc774\ubbf8\uc9c0\uc758 \ucd5c\ub300 \ud53d\uc140 \uac12 (8\ube44\ud2b8\uc758 \uacbd\uc6b0 255\uac00 \ucd5c\ub300\uac12)\n",
        "always_apply= Ture: \ubcc0\ud658\uc774 \ub370\uc774\ud130\uc14b\uc758 \ubaa8\ub4e0 \uc774\ubbf8\uc9c0\uc5d0 \ub300\ud574 \ud56d\uc0c1 \uc801\uc6a9.\n",
        "p: \ubcc0\ud658\uc774 \uc801\uc6a9\ub420 \ud655\ub960: (0~1 \uc0ac\uc774)\n",
        "\ub300\ubd80\ubd84\uc758 \uacbd\uc6b0 always_apply=True\ub85c \ud558\uace0 p\ub97c \uc870\uc808\ud574\uc11c \uc0ac\uc6a9 \n",
        "'''\n",
        "train_transform = A.Compose([\n",
        "    A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False,\n",
        "                p=1.0),\n",
        "    ToTensorV2()])\n",
        "\n",
        "test_transform = A.Compose([\n",
        "    A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False,\n",
        "                p=1.0),\n",
        "    ToTensorV2()])\n",
        "\n",
        "## train\ub370\uc774\ud130\uc14b \uc124\uc815 \ubc0f \ubd88\ub7ec\uc624\uae30\n",
        "train_dataset = CustomDataset(train['img_path'].values, train['label'].values, train_transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
        "\n",
        "## val \ub370\uc774\ud130\uc14b \uc124\uc815 \ubc0f \ubd88\ub7ec\uc624\uae30\n",
        "val_dataset = CustomDataset(val['img_path'].values, val['label'].values, test_transform)\n",
        "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
        "\n",
        "\n",
        "class BaseModel(nn.Module):\n",
        "    # le.classes\ub294 LabelEncoder\uac00 \ud559\uc2b5\ud55c \ud6c4\uc5d0 \uac16\uac8c\ub418\ub294 \uc18d\uc131 (\uace0\uc720\ud55c \ud074\ub798\uc2a4 \ub77c\ubca8\ub4e4\uc758 \ubc30\uc5f4)\n",
        "    def __init__(self, num_classes=len(le.classes_)):\n",
        "        super(BaseModel, self).__init__()\n",
        "        # EfficientNet B0 \uc544\ud0a4\ud14d\ucc98\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc0ac\uc804 \ud6c8\ub828\ub41c \ubc31\ubcf8 \uc124\uc815. \ud2b9\uc131 \ucd94\ucd9c\uae30 \uc5ed\ud568\n",
        "        self.backbone = models.efficientnet_b0(pretrained=True)\n",
        "        # \ubc31\ubcf8 \ubaa8\ub378\uc758 \ucd9c\ub825\uc744 \ubc1b\uc544 \ucd5c\uc885\uc801\uc73c\ub85c \ud074\ub798\uc2a4 \uc218\uc5d0 \ub9de\ub294 \ucd9c\ub825\uc744 \uc0dd\uc131\ud558\ub294 \uc120\ud615 \ubd84\ub958\uae30\n",
        "        self.classifier = nn.Linear(1000, num_classes)  # \uae30\ubcf8 \ucd9c\ub825\ud06c\uae30 1,000\uc73c\ub85c \uc815\uc758\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)  # backbone\uc744 \uac70\uccd0 \ud2b9\uc131\uc774 \ucd94\ucd9c\n",
        "        x = self.classifier(x)  # \ubd84\ub958\uae30\uc5d0 \uc804\ub2ec\ub418\uc5b4 \ucd5c\uc885 \ucd9c\ub825 \uc0dd\uc131\n",
        "        return x\n",
        "\n",
        "\n",
        "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
        "    model.to(device)  # \ubaa8\ub378\uc744 \ud574\ub2f9 \ub514\ubc14\uc774\uc2a4\ub85c \uc62e\uae40(cpu, gpu)\n",
        "    criterion = nn.CrossEntropyLoss().to(device)  # \uc190\uc2e4\ud568\uc218 \uc815\uc758\ud558\uace0 \ud574\ub2f9 device\ub85c \uc62e\uae40\n",
        "\n",
        "    # \uc131\ub2a5 \uae30\ub85d \ucd08\uae30\ud654\n",
        "    best_score = 0\n",
        "    best_model = None\n",
        "\n",
        "    # \uc124\uc815\ud55c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\uc758 epochs\ub9cc\ud07c \ubc18\ubcf5\n",
        "    for epoch in range(1, CFG['EPOCHS'] + 1):\n",
        "        model.train()  # \ubaa8\ub378\uc744 \ud6c8\ub828\ubaa8\ub4dc\ub85c \uc124\uc815\n",
        "        train_loss = []\n",
        "\n",
        "        # \ubc18\ubcf5\uc744 \ud1b5\ud574\uc11c \ubc30\uce58 \ub2e8\uc704\ub85c \uc774\ubbf8\uc9c0\uc640 \ub77c\ubca8\uc744 \uac00\uc838\uc634\n",
        "        for imgs, labels in tqdm(iter(train_loader)):\n",
        "            imgs = imgs.float().to(device)  # \uc774\ubbf8\uc9c0\ub97c \uc2e4\uc218\ud615\uc73c\ub85c \ubcc0\uacbd\ud55c \ud6c4 device\ub85c \uc62c\ub9bc\n",
        "            labels = labels.long().to(device)  # \ub370\uc774\ud130 \ud0c0\uc785 long\uc73c\ub85c \ubcc0\uacbd\ud55c \ud6c4 device\ub85c \uc62c\ub9bc (int\ub85c \ubcc0\uacbd\ud558\uc600\uc744 \ub54c, error \ubc1c\uc0dd\ud588\uc74c)\n",
        "\n",
        "            optimizer.zero_grad()  # \uc774\uc804 \uadf8\ub808\ub514\uc5b8\ud2b8\uac00 \ub204\uc801\ub420 \uac00\ub2a5\uc131\uc774 \uc788\uc73c\ub2c8 \ucd08\uae30\ud654\n",
        "\n",
        "            output = model(imgs)  # \ubaa8\ub378\uc758 \uc774\ubbf8\uc9c0\ub97c \uc785\ub825\ud558\uc5ec \ucd9c\ub825\uc744 \uc5bb\uc74c\n",
        "            loss = criterion(output, labels)  # \uc190\uc2e4 \ud568\uc218\ub97c \ud1b5\ud574 \uc190\uc2e4 \uac12\uc744 \uacc4\uc0b0\ud568.\n",
        "\n",
        "            loss.backward()  # \uc190\uc2e4\uc5d0 \ub300\ud55c \uadf8\ub808\ub514\uc5b8\ud2b8 \uacc4\uc0b0\n",
        "            optimizer.step()  # \uc635\ud2f0\ub9c8\uc774\uc800\ub97c \ud1b5\ud574 \ubaa8\ub378\uc758 \uac00\uc911\uce58 \uc5c5\ub370\uc774\ud2b8\n",
        "\n",
        "            train_loss.append(loss.item())  # loss.item()\uc740 \ud604\uc7ac \ubc30\uce58\uc5d0 \ub300\ud55c \uc190\uc2e4 \uac12\uc744 \ud30c\uc774\uc36c\uc758 floate \ud0c0\uc785\uc73c\ub85c \ubcc0\ud658.\n",
        "            # \ud6c8\ub828 \uacfc\uc815\uc5d0\uc11c \uac01 \ubc30\uce58\ub97c \ucc98\ub9ac\ud560 \ub54c\ub9c8\ub2e4 \uc774 \uc904\uc774 \uc2e4\ud589\ub418\uc5b4, \uac01 \ubc30\uce58\uc758 \uc190\uc2e4 \uac12\uc744 train_loss \ub9ac\uc2a4\ud2b8\uc5d0 \uc21c\ucc28\uc801\uc73c\ub85c \ucd94\uac00\n",
        "\n",
        "        # \uac01 \uc5d0\ud3ec\ud06c\ub9c8\ub2e4 validation\ud568\uc218\ub97c \ud638\ucd9c\ud558\uc5ec\uc11c \uac80\uc99d \uc138\ud2b8\uc5d0\uc11c \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ud3c9\uac00\n",
        "        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n",
        "        _train_loss = np.mean(train_loss)  # \uac01 \ubc30\uce58\uc5d0\uc11c \uacc4\uc0b0\ub41c \ubaa8\ub4e0 \uc190\uc2e4 \uac12\uc758 \ud3c9\uade0\uc744 \uad6c\ud568\n",
        "        print(\n",
        "            f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val F1 Score : [{_val_score:.5f}]')\n",
        "\n",
        "        # scheduler\uc774 \uc124\uc815\ub418\uc5b4 \uc788\ub2e4\uba74 \uac80\uc99d \uc131\ub2a5\uc5d0 \ub530\ub77c \ud559\uc2b5\ub960\uc744 \uc870\uc815\n",
        "        if scheduler is not None:\n",
        "            scheduler.step(_val_score)\n",
        "\n",
        "        # \uac00\uc7a5 \uc88b\uc740 \uc131\ub2a5\uc744 \ubcf4\uc778 \ubaa8\ub378\uc744 \ubc18\ud658\n",
        "        if best_score < _val_score:\n",
        "            best_score = _val_score\n",
        "            best_model = model\n",
        "\n",
        "    return best_model\n",
        "\n",
        "\n",
        "def validation(model, criterion, val_loader, device):\n",
        "    model.eval()  # \ud3c9\uac00\ubaa8\ub4dc\n",
        "    val_loss = []\n",
        "    preds, true_labels = [], []\n",
        "\n",
        "    # \ud3c9\uac00\ubaa8\ub4dc\uc758 \uacbd\uc6b0\uc5d0\ub294 gradient\ub97c \ucd08\uae30\ud654\ud558\ub294 \ubd80\ubd84\uc774 \uc5c6\uc74c (backward \ud544\uc694\uc5c6\uc74c. \uc624\uc9c1 \ud3c9\uac00\ub9cc!)\n",
        "    with torch.no_grad():  # \uc774 \ube14\ub85d \ub0b4\uc5d0\uc11c \uadf8\ub808\ub514\uc5b8\ud2b8 \uacc4\uc0b0\uc744 \uc911\ub2e8\ud558\uc5ec, \ud544\uc694\ud558\uc9c0 \uc54a\uc740 \uba54\ubaa8\ub9ac \uc0ac\uc6a9\uc744 \uc904\uc774\uace0 \uacc4\uc0b0 \uc18d\ub3c4 \ud5a5\uc0c1.\n",
        "        for imgs, labels in tqdm(iter(val_loader)):\n",
        "            imgs = imgs.float().to(device)\n",
        "            labels = labels.long().to(device)  # \ub370\uc774\ud130 \ud0c0\uc785 long\uc73c\ub85c \ubcc0\uacbd\ud55c \ud6c4 device\ub85c \uc62c\ub9bc (int\ub85c \ubcc0\uacbd\ud558\uc600\uc744 \ub54c, error \ubc1c\uc0dd\ud588\uc74c)\n",
        "\n",
        "            pred = model(imgs)\n",
        "\n",
        "            loss = criterion(pred, labels)\n",
        "\n",
        "            # pred\ub294 \ubaa8\ub378\uc774 \ubc18\ud658\ud55c \uc608\uce21\uac12. \uac01 \ud074\ub798\uc2a4\uc5d0 \ub300\ud55c \ud655\ub960 \ub610\ub294 \uc810\uc218\ub97c \ud3ec\ud568\ud558\ub294 \ud150\uc11c. argmax(1)\uc740 \uac01 \uc0d8\ud50c\uc5d0 \ub300\ud574 \uac00\uc7a5 \ub192\uc740 \uc810\uc218\ub97c \uac00\uc9c4 \ud074\ub798\uc2a4\uc758 \uc778\ub371\uc2a4\ub97c \ucc3e\uc544\uc90c.\n",
        "            # detach()\ub294 \ud604\uc7ac \uacc4\uc0b0 \uadf8\ub798\ud504\ub85c\ubd80\ud130 \uc774 \ud150\uc11c\ub97c \ubd84\ub9ac\ud558\uc5ec, \uc774\ud6c4 \uc5f0\uc0b0\uc774 \uadf8\ub798\ud504\uc5d0 \uae30\ub85d\ub418\uc9c0 \uc54a\ub3c4\ub85d\ud568. \uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub7c9 \uc904\uc784\n",
        "            # cpu()\ub294 cpu\ub85c \uc62e\uae40 (GPU\uc5d0 \uc788\uc5c8\ub2e4\uba74)\n",
        "            # numpy()\ub294 \ud150\uc11c\ub97c numpy \ubc30\uc5f4\ub85c \ubcc0\ud658\n",
        "            # tolist()\ub294 numpy \ubc30\uc5f4\uc744 \ud30c\uc774\uc36c \ub9ac\uc2a4\ud2b8\ub85c \ubcc0\ud658\n",
        "            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
        "\n",
        "            # \uc2e4\uc81c \ub77c\ubca8\ub3c4 \uc704\uc640 \ub3d9\uc77c\ud55c \uacfc\uc815 \uc9c4\ud589\n",
        "            true_labels += labels.detach().cpu().numpy().tolist()\n",
        "\n",
        "            val_loss.append(loss.item())\n",
        "\n",
        "        _val_loss = np.mean(val_loss)\n",
        "        # average = 'macro'\ub294 F1\uc810\uc218\ub97c \uacc4\uc0b0\ud560 \ub54c, \uac01 \ud074\ub798\uc2a4\uc5d0 \ub300\ud55c F1\uc810\uc218\ub97c \ub3d9\uc77c\ud55c \uac00\uc911\uce58\ub85c \ud3c9\uade0\ub0b4\uc5b4 \uc804\uccb4 \ud074\ub798\uc2a4\uc5d0 \ub300\ud55c \ud3c9\uade0 F1\uc810\uc218\ub97c \uacc4\uc0b0.\n",
        "        # \uac01 \ud074\ub798\uc2a4\uc758 \uc0d8\ud50c \ud06c\uae30\uc640 \uad00\uacc4\uc5c6\uc774 \ubaa8\ub4e0 \ud074\ub798\uc2a4\ub97c \ub3d9\ub4f1\ud558\uac8c \ucde8\uae09. \uc774\ub294 \ud074\ub798\uc2a4 \ubd88\uade0\ud615\uc774 \uc788\uc744 \ub54c \uc720\uc6a9\ud558\uba70, \ubaa8\ub4e0 \ud074\ub798\uc2a4\ub97c \uacf5\ud3c9\ud558\uac8c \ud3c9\uac00\ud558\uace0\uc790 \ud560 \ub54c \uc0ac\uc6a9.\n",
        "        _val_score = f1_score(true_labels, preds, average='macro')\n",
        "\n",
        "    return _val_loss, _val_score\n",
        "\n",
        "model = BaseModel() # \ubaa8\ub378\uc740 basemodel \uac00\uc838\uc634\n",
        "model.train() #\ud3c9\uac00\ubaa8\ub4dc\ub85c \uc804\ud658 (\ud6c8\ub828\ubaa8\ub4dc\uac00 \uc544\ub2cc \ud3c9\uac00\ubaa8\ub4dc\ub97c \ubd88\ub7ec\uc628 \uc774\uc720\uac00 \ubb50\uc9c0?..)\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"]) # optimizer 'adam'\uc73c\ub85c \uc124\uc815 / \ud559\uc2b5\ub960 \uc704\uc758 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\n",
        "\n",
        "#\ud559\uc2b5\ub960\uc744 \ub3d9\uc801\uc73c\ub85c \uc870\uc815\ud558\ub294 \uc2a4\ucf00\uc904\ub7ec \uc124\uc815. \uac80\uc99d \uc131\ub2a5\uc774 \uac1c\uc120\ub418\uc9c0 \uc54a\uc73c\uba74 \ud559\uc2b5\ub960 \uac10\uc18c.\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
        "\n",
        "infer_model = train(model, optimizer, train_loader, val_loader, scheduler, device)\n",
        "\n",
        "test = pd.read_csv('dataset/test.csv')\n",
        "# test['img_path'] = test['img_path'].apply(lambda x:os.path.join('dataset',x[1:]))\n",
        "test_dataset = CustomDataset(test['img_path'].values, None, test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
        "\n",
        "\n",
        "def inference(model, test_loader, device):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    with torch.no_grad():  # gradient \ucd08\uae30\ud654 \uc5c6\uc774 \ud3c9\uac00 \uc9c4\ud589\n",
        "        for imgs in tqdm(iter(test_loader)):\n",
        "            imgs = imgs.float().to(device)\n",
        "\n",
        "            pred = model(imgs)\n",
        "\n",
        "            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
        "\n",
        "    preds = le.inverse_transform(preds)\n",
        "    return preds\n",
        "\n",
        "\n",
        "preds = inference(infer_model, test_loader, device)\n",
        "\n",
        "submit = pd.read_csv('dataset/sample_submission.csv')\n",
        "submit['label'] = preds\n",
        "submit.to_csv('./baseline_submit.csv', index=False)"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}